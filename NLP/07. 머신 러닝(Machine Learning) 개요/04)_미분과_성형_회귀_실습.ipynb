{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04) 미분과 성형 회귀 실습.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhkOnMyAeb+t/JfkWK6tZb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2pterons/training/blob/main/NLP/07.%20%EB%A8%B8%EC%8B%A0%20%EB%9F%AC%EB%8B%9D(Machine%20Learning)%20%EA%B0%9C%EC%9A%94/04)_%EB%AF%B8%EB%B6%84%EA%B3%BC_%EC%84%B1%ED%98%95_%ED%9A%8C%EA%B7%80_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 04) 미분과 성형 회귀 실습"
      ],
      "metadata": {
        "id": "HkC7yyhyPvfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 자동 미분"
      ],
      "metadata": {
        "id": "CVm092ELQOKX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "0C3dkZ4WPqpx"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "tape_grandient()는 자동 미분 기능을 수행합니다. 임의로 $2w^2+5$라는 식을 세워보고, $w$에 대해 미분해보겠습니다."
      ],
      "metadata": {
        "id": "mHGge5qlQSAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = tf.Variable(2.)\n",
        "\n",
        "def f(w):\n",
        "  y = w**2\n",
        "  z = 2*y + 5\n",
        "  return z"
      ],
      "metadata": {
        "id": "HAtRoAVmQQ8t"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "gradients를 출력하면 $w$에 대해 미분한 값이 저장된 것을 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "ZaO9bUXlQ5vF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.GradientTape() as tape:\n",
        "  z = f(w)\n",
        "\n",
        "gradients = tape.gradient(z, [w])\n",
        "print(gradients)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZtnNjBtQ_I8",
        "outputId": "43c988da-9c6f-4378-cb1c-2861937bef5b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 자동 미분 기능을 사용하여 선형 회귀를 구현해봅시다."
      ],
      "metadata": {
        "id": "zIg3LJPiRp-L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br/><br/>\n",
        "# 자동 미분을 이용한 선형 회귀 구현"
      ],
      "metadata": {
        "id": "4c36ANcwRuyc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "우선 가중치 변수 w와 b를 선언합니다. 학습될 값이므로 임의의 값인 4와 1로 초기화하였습니다."
      ],
      "metadata": {
        "id": "DGRr5oKkRwcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습될 가중치 변수를 선언\n",
        "w = tf.Variable(4.0)\n",
        "b = tf.Variable(1.0)"
      ],
      "metadata": {
        "id": "M4T-0DtYR_yx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "가설을 함수로서 정의합니다."
      ],
      "metadata": {
        "id": "gBBRPfAjSCSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def hypothesis(x):\n",
        "  return w*x + b"
      ],
      "metadata": {
        "id": "dZdOHyyMSEyb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "현재의 가설에서 w와 b는 각각 4와 1이므로 임의의 입력값을 넣었을 때의 결과는 다음과 같습니다."
      ],
      "metadata": {
        "id": "jmjeHY1FSJ7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = [3.5, 5, 5.5, 6]\n",
        "print(hypothesis(x_test).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sm0hXNRFSPpS",
        "outputId": "220e7b0f-4d41-48a8-b4bc-23753625155d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15. 21. 23. 25.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "다음과 같이 평균 제곱 오차를 손실 함수로서 정의합니다."
      ],
      "metadata": {
        "id": "xbk3XNcOU6Nd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@tf.function\n",
        "def mse_loss(y_pred, y):\n",
        "  # 두 개의 차이값을 제곱을 해서 평균을 취한다.\n",
        "  return tf.reduce_mean(tf.square(y_pred - y))"
      ],
      "metadata": {
        "id": "KndvVRYIU-Qw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "여기서 사용할 데이터는 x와 y가 약 10배의 차이를 가지는 데이터입니다."
      ],
      "metadata": {
        "id": "Lw0cmNCkVJ65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = [1, 2, 3, 4, 5, 6, 7, 8, 9] # 공부하는 성적\n",
        "y = [11, 22, 33, 44, 55, 66, 77, 87, 95] # 각 공부하는 시간에 맵핑되는 성적"
      ],
      "metadata": {
        "id": "xTM_R6XzVN1_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "옵티마이저는 경사 하강법을 사용하되, 학습률(learning rate)는 0.01을 사용합니다."
      ],
      "metadata": {
        "id": "sbFKRIcSVXlx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.optimizers.SGD(0.01)\n"
      ],
      "metadata": {
        "id": "l5TRSIwNVb5L"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "약 300번에 걸쳐서 경사 하강법을 수행하겠습니다."
      ],
      "metadata": {
        "id": "Va7NK8YvVeWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(301):\n",
        "  with tf.GradientTape() as tape:\n",
        "    # 현재 파라미터에 기반한 입력 x에 대한 예측값을 y_pred\n",
        "    y_pred = hypothesis(x)\n",
        "\n",
        "    # 평균 제곱 오차를 계산\n",
        "    cost = mse_loss(y_pred, y)\n",
        "\n",
        "  # 손실 함수에 대한 파라미터의 미분값 계산\n",
        "  gradients = tape.gradient(cost, [w, b])\n",
        "\n",
        "  # 파라미터 업데이트\n",
        "  optimizer.apply_gradient(zip(gradients, [w, b]))\n",
        "\n",
        "  if i % 10 == 0:\n",
        "    print(\"epoch : {:3} | w의 값 : {:5.4f} | b의 값 : {:5.4} | cost : {:5.6f}\".format(i, w.numpy(), b.nummpy(), cost))\n",
        "    "
      ],
      "metadata": {
        "id": "eBrIVSkHVhQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "w와 b값이 계속 업데이트 됨에 따라서 cost가 지속적으로 줄어드는 것을 확인할 수 있습니다. 학습된 w와 b의 값에 대해서 임의 입력을 넣었을 경우의 예측값을 확인해봅시다."
      ],
      "metadata": {
        "id": "7dkJUXjIW0j6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = [3.5, 5, 5.5, 6]\n",
        "print(hypothesis(x_test).numpy())"
      ],
      "metadata": {
        "id": "M-3ModJhW1Kj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}